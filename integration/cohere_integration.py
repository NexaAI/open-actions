import os
import json
from dotenv import load_dotenv
import cohere
import sys
from pathlib import Path

# This will get the path of the current script and then find the root of the project directory.
current_dir = Path(__file__).resolve().parent
project_dir = current_dir.parent  # Assuming 'integration' is directly under the project root
sys.path.append(str(project_dir))

# Now you can import your module
from actions.content_creator.new_york_times_top_stories_api import new_york_times_top_stories


load_dotenv()
COHERE_API_KEY = os.getenv("COHERE_API_KEY")

co = cohere.Client(
    api_key=COHERE_API_KEY,
)

# tool descriptions that the model has access to
# note: Cohere always adds a "directly_answer" tool under the hood, so that the model can decide to not leverage any tool, if they're not needed.
tools = [
    {
        "name": "new_york_times_top_stories",
        "description": "Get the top stories from The New York Times for a given section.",
        "parameter_definitions": {
            "section": {
                "description": "The section the story appears in. The following values are allowed:arts, automobiles, books/review, business, fashion, food, health, home, insider, magazine, movies, nyregion, obituaries, opinion, politics, realestate, science, sports, sundayreview, technology, theater, t-magazine, travel, upshot, us, world.",
                "type": "str",
                "required": True
            }
        }
    }
]

# preamble containing instructions about the task and the desired style for the output.
preamble = """
## Task & Context
You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.

## Style Guide
Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.
"""

# user request
message = "tell me top stories in art in new york times."

response = co.chat(
    message=message,
    tools=tools,
    preamble=preamble,
    model="command-r"
)

# Note that the Cohere Chat API also exposes:
# - stream (for streaming mode)
# - chat_history
# - among other parameters
# See https://docs.cohere.com/reference/chat for details.

print("The model recommends doing the following tool calls:")
print("\n".join(str(tool_call) for tool_call in response.tool_calls))

tool_results = []
# Iterate over the tool calls generated by the model
for tool_call in response.tool_calls:
    # here is where you would call the tool recommended by the model, using the parameters recommended by the model
    print(f"= running tool {tool_call.name}, with parameters: {tool_call.parameters}")
    
    # Assuming new_york_times_top_stories is a synchronous function. If it's asynchronous, you'll need to await it
    output = new_york_times_top_stories(**tool_call.parameters)
    
    # Directly print the function output
    print("== Function output:")
    print(output)
    
    # Additionally, if you wish to store the output in a list for further processing or logging
    outputs = [output]

response = co.chat(
    message=message,
    tools=tools,
    tool_results=tool_results,
    preamble=preamble,
    model="command-r",
    temperature=0.3
)

print("Final answer:")
print(response.text)